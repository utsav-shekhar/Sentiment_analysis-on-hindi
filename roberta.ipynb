{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7836180,"sourceType":"datasetVersion","datasetId":4593295},{"sourceId":7836247,"sourceType":"datasetVersion","datasetId":4593339},{"sourceId":7836267,"sourceType":"datasetVersion","datasetId":4593354}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing the libraries needed\n# !pip install transformers==3.0.2\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport seaborn as sns\nimport transformers\nimport json\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaModel, RobertaTokenizer\nimport logging\nlogging.basicConfig(level=logging.ERROR)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T16:52:38.679604Z","iopub.execute_input":"2024-03-15T16:52:38.679860Z","iopub.status.idle":"2024-03-15T16:52:48.041541Z","shell.execute_reply.started":"2024-03-15T16:52:38.679837Z","shell.execute_reply":"2024-03-15T16:52:48.040585Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Setting up the device for GPU usage\n\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.043326Z","iopub.execute_input":"2024-03-15T16:52:48.044226Z","iopub.status.idle":"2024-03-15T16:52:48.075064Z","shell.execute_reply.started":"2024-03-15T16:52:48.044181Z","shell.execute_reply":"2024-03-15T16:52:48.074167Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/train-tsv/train.tsv', delimiter='\\t')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.076320Z","iopub.execute_input":"2024-03-15T16:52:48.076688Z","iopub.status.idle":"2024-03-15T16:52:48.395780Z","shell.execute_reply.started":"2024-03-15T16:52:48.076654Z","shell.execute_reply":"2024-03-15T16:52:48.394772Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.398167Z","iopub.execute_input":"2024-03-15T16:52:48.398515Z","iopub.status.idle":"2024-03-15T16:52:48.414009Z","shell.execute_reply.started":"2024-03-15T16:52:48.398489Z","shell.execute_reply":"2024-03-15T16:52:48.412956Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   PhraseId  SentenceId                                             Phrase  \\\n0         1           1  A series of escapades demonstrating the adage ...   \n1         2           1  A series of escapades demonstrating the adage ...   \n2         3           1                                           A series   \n3         4           1                                                  A   \n4         5           1                                             series   \n\n   Sentiment  \n0          1  \n1          2  \n2          2  \n3          2  \n4          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>A series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>series</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Specify the paths to the Parquet files\nparquet_file_path1 = \"/kaggle/input/hindi-sentiments/train-00000-of-00001.parquet\"\nparquet_file_path2 = \"/kaggle/input/hindi-sa/train-00000-of-00001 (1).parquet\"\n\n# Read the Parquet files into pandas DataFrames\ndf1 = pd.read_parquet(parquet_file_path1)\ndf2 = pd.read_parquet(parquet_file_path2)\ndf = pd.concat([df1, df2], ignore_index=True)\ndf = df.sample(frac=1).reset_index(drop=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.415021Z","iopub.execute_input":"2024-03-15T16:52:48.415346Z","iopub.status.idle":"2024-03-15T16:52:48.708668Z","shell.execute_reply.started":"2024-03-15T16:52:48.415322Z","shell.execute_reply":"2024-03-15T16:52:48.707698Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.709935Z","iopub.execute_input":"2024-03-15T16:52:48.710290Z","iopub.status.idle":"2024-03-15T16:52:48.719286Z","shell.execute_reply.started":"2024-03-15T16:52:48.710257Z","shell.execute_reply":"2024-03-15T16:52:48.718467Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  हालाकि इसमें दो स्‍क्रीन की खूबी दी गई थी जिसम...      1\n1  इसके जरिये आप इन‍कमिंग मैसेज का रिप्‍लाई भी कर...      1\n2  अगर केतन केहता की 'रंग रसिया' समय से रिलीज हो ...      1\n3  यह डिसप्ले ज्यादातर मामलों में अच्छा प्रदर्शन ...      2\n4  इसका नाम बदलकर केवलादेव घना नेशनल पार्क रखा गया ।      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>हालाकि इसमें दो स्‍क्रीन की खूबी दी गई थी जिसम...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>इसके जरिये आप इन‍कमिंग मैसेज का रिप्‍लाई भी कर...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>अगर केतन केहता की 'रंग रसिया' समय से रिलीज हो ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>यह डिसप्ले ज्यादातर मामलों में अच्छा प्रदर्शन ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>इसका नाम बदलकर केवलादेव घना नेशनल पार्क रखा गया ।</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.720269Z","iopub.execute_input":"2024-03-15T16:52:48.720568Z","iopub.status.idle":"2024-03-15T16:52:48.732531Z","shell.execute_reply.started":"2024-03-15T16:52:48.720545Z","shell.execute_reply":"2024-03-15T16:52:48.731631Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([1, 2, 0])"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.733809Z","iopub.execute_input":"2024-03-15T16:52:48.734499Z","iopub.status.idle":"2024-03-15T16:52:48.753069Z","shell.execute_reply.started":"2024-03-15T16:52:48.734463Z","shell.execute_reply":"2024-03-15T16:52:48.752125Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             label\ncount  6662.000000\nmean      1.234164\nstd       0.756368\nmin       0.000000\n25%       1.000000\n50%       1.000000\n75%       2.000000\nmax       2.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6662.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.234164</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.756368</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_df = df[['text', 'label']]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.754158Z","iopub.execute_input":"2024-03-15T16:52:48.754494Z","iopub.status.idle":"2024-03-15T16:52:48.760751Z","shell.execute_reply.started":"2024-03-15T16:52:48.754464Z","shell.execute_reply":"2024-03-15T16:52:48.759737Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.765780Z","iopub.execute_input":"2024-03-15T16:52:48.766066Z","iopub.status.idle":"2024-03-15T16:52:48.775631Z","shell.execute_reply.started":"2024-03-15T16:52:48.766044Z","shell.execute_reply":"2024-03-15T16:52:48.774770Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  हालाकि इसमें दो स्‍क्रीन की खूबी दी गई थी जिसम...      1\n1  इसके जरिये आप इन‍कमिंग मैसेज का रिप्‍लाई भी कर...      1\n2  अगर केतन केहता की 'रंग रसिया' समय से रिलीज हो ...      1\n3  यह डिसप्ले ज्यादातर मामलों में अच्छा प्रदर्शन ...      2\n4  इसका नाम बदलकर केवलादेव घना नेशनल पार्क रखा गया ।      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>हालाकि इसमें दो स्‍क्रीन की खूबी दी गई थी जिसम...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>इसके जरिये आप इन‍कमिंग मैसेज का रिप्‍लाई भी कर...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>अगर केतन केहता की 'रंग रसिया' समय से रिलीज हो ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>यह डिसप्ले ज्यादातर मामलों में अच्छा प्रदर्शन ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>इसका नाम बदलकर केवलादेव घना नेशनल पार्क रखा गया ।</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Defining some key variables that will be used later on in the training\nMAX_LEN = 256\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 4\n# EPOCHS = 1\nLEARNING_RATE = 0.00001\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:48.776685Z","iopub.execute_input":"2024-03-15T16:52:48.776939Z","iopub.status.idle":"2024-03-15T16:52:50.640916Z","shell.execute_reply.started":"2024-03-15T16:52:48.776918Z","shell.execute_reply":"2024-03-15T16:52:50.640054Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a85a730bb9481ea6091a50064060a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b342ad7b2b141789eba767a64bd88b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cdd58e11b774eadb5f4851ceac73f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b42d1f41bf4247e19672a3c49d37e495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36e2ead26a364833880af0ed153304ef"}},"metadata":{}}]},{"cell_type":"code","source":"class SentimentData(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe.text\n        self.targets = self.data.label\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:50.642104Z","iopub.execute_input":"2024-03-15T16:52:50.642402Z","iopub.status.idle":"2024-03-15T16:52:50.652553Z","shell.execute_reply.started":"2024-03-15T16:52:50.642378Z","shell.execute_reply":"2024-03-15T16:52:50.651433Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ntrain_data=new_df.sample(frac=train_size,random_state=200)\ntest_data=new_df.drop(train_data.index).reset_index(drop=True)\ntrain_data = train_data.reset_index(drop=True)\n\n\nprint(\"FULL Dataset: {}\".format(new_df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_data.shape))\nprint(\"TEST Dataset: {}\".format(test_data.shape))\n\ntraining_set = SentimentData(train_data, tokenizer, MAX_LEN)\ntesting_set = SentimentData(test_data, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:50.653590Z","iopub.execute_input":"2024-03-15T16:52:50.653835Z","iopub.status.idle":"2024-03-15T16:52:50.674082Z","shell.execute_reply.started":"2024-03-15T16:52:50.653813Z","shell.execute_reply":"2024-03-15T16:52:50.673216Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"FULL Dataset: (6662, 2)\nTRAIN Dataset: (5330, 2)\nTEST Dataset: (1332, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:50.675151Z","iopub.execute_input":"2024-03-15T16:52:50.675444Z","iopub.status.idle":"2024-03-15T16:52:50.682131Z","shell.execute_reply.started":"2024-03-15T16:52:50.675395Z","shell.execute_reply":"2024-03-15T16:52:50.681213Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class RobertaClass(torch.nn.Module):\n    def __init__(self):\n        super(RobertaClass, self).__init__()\n        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(768, 5)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:50.683156Z","iopub.execute_input":"2024-03-15T16:52:50.683470Z","iopub.status.idle":"2024-03-15T16:52:50.694196Z","shell.execute_reply.started":"2024-03-15T16:52:50.683442Z","shell.execute_reply":"2024-03-15T16:52:50.693495Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = RobertaClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:50.695136Z","iopub.execute_input":"2024-03-15T16:52:50.695382Z","iopub.status.idle":"2024-03-15T16:52:53.699851Z","shell.execute_reply.started":"2024-03-15T16:52:50.695361Z","shell.execute_reply":"2024-03-15T16:52:53.698951Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16bb1fd59a2a49cca78919ed65e20579"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"RobertaClass(\n  (l1): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Creating the loss function and optimizer\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:53.701224Z","iopub.execute_input":"2024-03-15T16:52:53.701490Z","iopub.status.idle":"2024-03-15T16:52:53.707034Z","shell.execute_reply.started":"2024-03-15T16:52:53.701468Z","shell.execute_reply":"2024-03-15T16:52:53.706176Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def calcuate_accuracy(preds, targets):\n    n_correct = (preds==targets).sum().item()\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:53.708102Z","iopub.execute_input":"2024-03-15T16:52:53.708471Z","iopub.status.idle":"2024-03-15T16:52:53.860283Z","shell.execute_reply.started":"2024-03-15T16:52:53.708438Z","shell.execute_reply":"2024-03-15T16:52:53.859355Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(epoch):\n    tr_loss = 0\n    n_correct = 0\n    nb_tr_steps = 0\n    nb_tr_examples = 0\n    model.train()\n    \n    # Wrap training_loader with tqdm for progress tracking\n    for _, data in enumerate(tqdm(training_loader, desc=f\"Epoch {epoch}\")):\n        ids = data['ids'].to(device, dtype=torch.long)\n        mask = data['mask'].to(device, dtype=torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n        targets = data['targets'].to(device, dtype=torch.long)\n\n        outputs = model(ids, mask, token_type_ids)\n        loss = loss_function(outputs, targets)\n        tr_loss += loss.item()\n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        n_correct += calcuate_accuracy(big_idx, targets)\n\n        nb_tr_steps += 1\n        nb_tr_examples += targets.size(0)\n        \n        if nb_tr_steps % 5000 == 0:\n            loss_step = tr_loss / nb_tr_steps\n            accu_step = (n_correct * 100) / nb_tr_examples \n            print(f\"Training Loss per 5000 steps: {loss_step}\")\n            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n    epoch_loss = tr_loss / nb_tr_steps\n    epoch_accu = (n_correct * 100) / nb_tr_examples\n    print(f\"Training Loss Epoch: {epoch_loss}\")\n    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n\nEPOCHS = 14\nfor epoch in range(EPOCHS):\n    train(epoch)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:52:53.862035Z","iopub.execute_input":"2024-03-15T16:52:53.862393Z","iopub.status.idle":"2024-03-15T17:22:17.633716Z","shell.execute_reply.started":"2024-03-15T16:52:53.862360Z","shell.execute_reply":"2024-03-15T17:22:17.632817Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Epoch 0:   0%|          | 0/334 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nEpoch 0: 100%|██████████| 334/334 [02:06<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 0: 40.61913696060037\nTraining Loss Epoch: 1.1073498656292875\nTraining Accuracy Epoch: 40.61913696060037\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 1: 43.63977485928705\nTraining Loss Epoch: 1.0594262518211752\nTraining Accuracy Epoch: 43.63977485928705\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 334/334 [02:05<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 2: 50.150093808630395\nTraining Loss Epoch: 0.9947055008953917\nTraining Accuracy Epoch: 50.150093808630395\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 3: 53.26454033771107\nTraining Loss Epoch: 0.9562325543629195\nTraining Accuracy Epoch: 53.26454033771107\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 4: 55.40337711069419\nTraining Loss Epoch: 0.9106192606651854\nTraining Accuracy Epoch: 55.40337711069419\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 5: 57.87992495309568\nTraining Loss Epoch: 0.8664897288123291\nTraining Accuracy Epoch: 57.87992495309568\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 6: 60.75046904315197\nTraining Loss Epoch: 0.8383265109119301\nTraining Accuracy Epoch: 60.75046904315197\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 7: 62.4015009380863\nTraining Loss Epoch: 0.807985848206246\nTraining Accuracy Epoch: 62.4015009380863\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 334/334 [02:06<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 8: 63.86491557223265\nTraining Loss Epoch: 0.7814325184343818\nTraining Accuracy Epoch: 63.86491557223265\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 9: 65.29080675422139\nTraining Loss Epoch: 0.7531841788106336\nTraining Accuracy Epoch: 65.29080675422139\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 10: 67.5234521575985\nTraining Loss Epoch: 0.7129041882689128\nTraining Accuracy Epoch: 67.5234521575985\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 11: 69.30581613508443\nTraining Loss Epoch: 0.6820704017035262\nTraining Accuracy Epoch: 69.30581613508443\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 334/334 [02:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 12: 72.13883677298311\nTraining Loss Epoch: 0.640739407724963\nTraining Accuracy Epoch: 72.13883677298311\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 334/334 [02:06<00:00,  2.65it/s]","output_type":"stream"},{"name":"stdout","text":"The Total Accuracy for Epoch 13: 72.77673545966229\nTraining Loss Epoch: 0.6156333695182543\nTraining Accuracy Epoch: 72.77673545966229\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, recall_score\n\nmodel.eval()  # Set the model to evaluation mode\ntotal_correct = 0\ntotal_samples = 0\n\n# For F1 and recall calculation\nall_predicted_labels = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        # Move batch to device\n        batch = {k: v.to(device) for k, v in batch.items()}\n        \n        # Forward pass\n        outputs = model(**batch)\n        \n        # Compute predictions\n        predicted_labels = torch.argmax(outputs.logits, dim=1)\n        \n        # Update total number of correct predictions\n        total_correct += (predicted_labels == batch[\"labels\"]).sum().item()\n        \n        # Update total number of samples\n        total_samples += len(batch[\"labels\"])\n        \n        # Collect predicted and true labels for F1 and recall calculation\n        all_predicted_labels.extend(predicted_labels.cpu().numpy())\n        all_true_labels.extend(batch[\"labels\"].cpu().numpy())\n\n# Calculate accuracy\naccuracy = total_correct / total_samples\nprint(f\"Model accuracy on test set: {accuracy}\")\n\n# Calculate F1 score and recall\nf1 = f1_score(all_true_labels, all_predicted_labels, average='weighted')\nrecall = recall_score(all_true_labels, all_predicted_labels, average='weighted')\n\nprint(f\"F1 score on test set: {f1}\")\nprint(f\"Recall on test set: {recall}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T17:49:13.672197Z","iopub.execute_input":"2024-03-15T17:49:13.672937Z","iopub.status.idle":"2024-03-15T17:49:13.730789Z","shell.execute_reply.started":"2024-03-15T17:49:13.672904Z","shell.execute_reply":"2024-03-15T17:49:13.729483Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m all_true_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_loader\u001b[49m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Move batch to device\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"],"ename":"NameError","evalue":"name 'test_loader' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}